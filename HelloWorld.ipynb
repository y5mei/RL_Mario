{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Check if GPU is available for training on your device:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) # this should return \"Num GPUs Available:  1\" if tensorflow can use your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available() # this should return True is PyTorch can use GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Install the Super Mario Environment, change the color frame to GrayScale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "pip install gym_super_mario_bros nes_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, RIGHT_ONLY, COMPLEX_MOVEMENT\n",
    "# Import Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "# Import Vectorization Wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "# Import Matplotlib to show the impact of frame stacking\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Training for Mario\n",
    "[The Mario Training Algo, PPO: Proximal Policy Optimization Algorithms](chrome-extension://dagcmkpagjlhakfdhnbomgmjdpkdklff/enhanced-reader.html?openApp&pdf=https%3A%2F%2Farxiv.org%2Fpdf%2F1707.06347.pdf)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "# 1. Create the base environment\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "# 2. Simplify the controls\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# 3. Grayscale\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "# 4. Wrap inside the Dummy Environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# 5. Stack the frames\n",
    "env = VecFrameStack(env, 8, channels_order='last')\n",
    "model = PPO('CnnPolicy', env, verbose=1, learning_rate=0.0001,\n",
    "            n_steps=128, device=\"auto\") # print out verbose training information every 128 steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 93  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 1   |\n",
      "|    total_timesteps | 128 |\n",
      "----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 256         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016734052 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.00191     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 384         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028258791 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0485     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 512         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012291038 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0153     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 640         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018063767 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.00527     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.24        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 768         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043142673 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.139      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.61        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    value_loss           | 9.82        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 71         |\n",
      "|    total_timesteps      | 896        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01982091 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | -0.0317    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.04       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    value_loss           | 8.75       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020404203 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.41        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    value_loss           | 6.65        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the AI model, this is where the AI model starts to learn\n",
    "model.learn(total_timesteps=1024)\n",
    "model.save('thisisatestmodel')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the trained Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensor\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = PPO.load('thisisatestmodel')\n",
    "state = env.reset()\n",
    "# Start the game\n",
    "state = env.reset()\n",
    "# Loop through the game\n",
    "cnt = 0\n",
    "while True and cnt < 1024:\n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    cnt+=1\n",
    "    env.render()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
